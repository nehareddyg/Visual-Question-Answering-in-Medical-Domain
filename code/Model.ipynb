{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "LAXFvRu4AjIA"
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "import collections\n",
    "import tensorflow as tf \n",
    "import re\n",
    "import h5py\n",
    "import argparse\n",
    "import sys \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD PREPROCESSED TRAINING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load necessary files: Here we have loaded file for training\n",
    "df_final = pickle.load(open('train_df_final.pkl', 'rb'))\n",
    "features = pickle.load(open('image_feature_train.pkl', 'rb'))\n",
    "word_to_idx = pickle.load(open('word_to_idx.pkl', 'rb'))\n",
    "idx_to_word = pickle.load(open('idx_to_word.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "WMrwspRWAjIo"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, merge, LSTM, Dropout, Dense, RepeatVector, BatchNormalization, \\\n",
    "    TimeDistributed, Flatten, Reshape\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1771,
     "status": "ok",
     "timestamp": 1526397490874,
     "user": {
      "displayName": "meghana kotagiri",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108948321362643567286"
     },
     "user_tz": -330
    },
    "id": "Zpnvy_e5AjI2",
    "outputId": "c8d52205-ab4c-4fe5-99e6-3155ed3fd32b"
   },
   "outputs": [],
   "source": [
    "vocabulary_size=len(word_to_idx)\n",
    "embed_size=150\n",
    "question_max_len=PADDING_LEN-1\n",
    "answer_max_len=PADDING_LEN-1\n",
    "# Image\n",
    "k_image_input = Input(shape=(4096,))\n",
    "k_image_repeat = RepeatVector(n=question_max_len)(k_image_input)\n",
    "\n",
    "# Question\n",
    "k_question_input = Input(shape=(question_max_len,), dtype='int32')\n",
    "k_question_embedded = Embedding(input_dim=vocabulary_size, output_dim=embed_size, input_length=question_max_len)(k_question_input)  \n",
    "k_question_embedded = Dropout(0.3)(k_question_embedded)\n",
    "\n",
    "# Merge\n",
    "k_merged = merge([k_image_repeat, k_question_embedded], mode='concat')  # Merge for layers merge for tensors\n",
    "k_merged = BatchNormalization()(k_merged)\n",
    "\n",
    "#Set encoder\n",
    "k_encoder_outputs, k_state_h, k_state_c  = LSTM(embed_size, return_state=True)(k_merged)\n",
    "k_encoder_outputs = Dropout(0.3)(k_encoder_outputs)\n",
    "k_encoder_states = [k_state_h, k_state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "k_decoder_inputs = Input(shape=(None, vocabulary_size))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "k_decoder_lstm = LSTM(embed_size, return_sequences=True, return_state=True)\n",
    "k_decoder_outputs, _, _ = k_decoder_lstm(k_decoder_inputs, initial_state=k_encoder_states)\n",
    "\n",
    "#Final Layer\n",
    "k_decoder_dense = Dense(vocabulary_size, activation='softmax')\n",
    "k_decoder_outputs = k_decoder_dense(k_decoder_outputs)\n",
    "\n",
    "model = Model([k_image_input, k_question_input, k_decoder_inputs], k_decoder_outputs)\n",
    "print('Model created')\n",
    "print('Compiling model...')\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "print('Model compiled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "rIg9hcSTAjI9"
   },
   "outputs": [],
   "source": [
    "image_input=np.array(features)\n",
    "question_inputs=np.array(df_final['Q_Encoded'])\n",
    "question_inputs=np.array([np.array(item) for item in question_inputs])\n",
    "decoder_inputs =np.array(df_final['A_Encoded'])\n",
    "decoder_targets =np.array(df_final['A_Encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "stHJGreOAjJA"
   },
   "outputs": [],
   "source": [
    "m_decoder_inputs = np.zeros(\n",
    "    (len(decoder_inputs), PADDING_LEN-1, vocabulary_size),\n",
    "    dtype='float32')\n",
    "m_decoder_targets= np.zeros(\n",
    "    (len(decoder_targets), PADDING_LEN-1, vocabulary_size),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(question_inputs, decoder_inputs)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        m_question_input_data[i, t, char] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        m_decoder_inputs[i, t, char] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            m_decoder_targets[i, t - 1, char] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3471
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 746465,
     "status": "ok",
     "timestamp": 1526398245787,
     "user": {
      "displayName": "meghana kotagiri",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108948321362643567286"
     },
     "user_tz": -330
    },
    "id": "dsrPk7ghAjJI",
    "outputId": "3fffbffc-b3b0-4631-daed-27a1e9f6f002",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit([features,question_inputs, m_decoder_inputs], m_decoder_targets, batch_size=100, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1102,
     "status": "ok",
     "timestamp": 1526397094952,
     "user": {
      "displayName": "meghana kotagiri",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108948321362643567286"
     },
     "user_tz": -330
    },
    "id": "626KfYHMj8FJ",
    "outputId": "6b5bac4a-3db0-45f4-c6bb-7fc41b5fb43a"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model([k_image_input,k_question_input], k_encoder_states)\n",
    "decoder_state_input_h = Input(shape=(embed_size,))\n",
    "decoder_state_input_c = Input(shape=(embed_size,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = k_decoder_lstm(k_decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = k_decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([k_decoder_inputs] + decoder_states_inputs,[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "dKbxNsgl2oV2"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(image_features,input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "  \n",
    "    states_value = encoder_model.predict([image_features,input_seq])\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, vocabulary_size))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, 1] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx_to_word[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        decoded_sentence +=\" \"\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '2' or\n",
    "           len(decoded_sentence) > PADDING_LEN-1):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, vocabulary_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD PREPROCESSED TEST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1094,
     "status": "ok",
     "timestamp": 1526389448037,
     "user": {
      "displayName": "meghana kotagiri",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108948321362643567286"
     },
     "user_tz": -330
    },
    "id": "ZiXFyaF-44yL",
    "outputId": "41c795f5-6f75-446f-c9b4-20614c1b7b9b"
   },
   "outputs": [],
   "source": [
    "#Open inputs of test dataset\n",
    "file = open('image_feature_test.pkl', 'rb')\n",
    "features_test = pickle.load(file)\n",
    "file2 = open('test_df_v_final', 'rb')\n",
    "df_test= pickle.load(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "g1CgYY317OIv"
   },
   "outputs": [],
   "source": [
    "test_questions=np.array(df_test['Q_Encoded'])\n",
    "test_questions=np.array([np.array(item) for item in test_questions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "zd4IUqICJWZd"
   },
   "outputs": [],
   "source": [
    "#use model to predict the answer\n",
    "predicted_answers_test=[]\n",
    "for seq_index in range(len(df_test)):\n",
    "    input_seq = test_questions[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(features_test[seq_index: seq_index + 1], input_seq)\n",
    "    predicted_answers_test.append(decoded_sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 8466
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1214,
     "status": "ok",
     "timestamp": 1526397134106,
     "user": {
      "displayName": "meghana kotagiri",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108948321362643567286"
     },
     "user_tz": -330
    },
    "id": "sxFhH1HjEP1I",
    "outputId": "cbb8982f-2b07-492b-cf6f-905153909eae"
   },
   "outputs": [],
   "source": [
    "predicted_answers_test=[item[0:len(item)-1] for item in predicted_answers_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "gU5UiHfl8eeY"
   },
   "outputs": [],
   "source": [
    "#function used to remove end tokens from the predicted answers\n",
    "def find_end(item,st):\n",
    "    for i in range(0,len(item)):\n",
    "        if item[i]==st:\n",
    "            return i\n",
    "    return i+1  \n",
    "predicted_answers_test=[item[0:find_end(item,'<END>')] for item in predicted_answers_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 12852
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1228,
     "status": "ok",
     "timestamp": 1526390575918,
     "user": {
      "displayName": "meghana kotagiri",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108948321362643567286"
     },
     "user_tz": -330
    },
    "id": "0ZghtCFd9Pqv",
    "outputId": "a28a635a-707e-449f-edf6-e02f502c10c7"
   },
   "outputs": [],
   "source": [
    "#actual/target answers\n",
    "test_answers=np.array(df_test['A_parsed'])\n",
    "test_answers=[item for item in test_answers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1606,
     "status": "ok",
     "timestamp": 1526397215547,
     "user": {
      "displayName": "meghana kotagiri",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108948321362643567286"
     },
     "user_tz": -330
    },
    "id": "wUoB0zSK-D8w",
    "outputId": "689e45c8-d6e5-4afa-d6a6-95eacd932ca2"
   },
   "outputs": [],
   "source": [
    "#Final BLEU Score\n",
    "score = corpus_bleu(test_answers, predicted_answers_test)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "keras ass.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
